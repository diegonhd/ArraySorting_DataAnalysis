Com base nas imagens que vocÃª enviou, a estrutura do repositÃ³rio mudou ligeiramente. O notebook de geraÃ§Ã£o de dados e os arquivos `.npy` estÃ£o dentro de uma pasta chamada `array archive`, enquanto o notebook de anÃ¡lise (`sort_benchmark.ipynb`) e os CSVs de resultados estÃ£o na raiz.

Aqui estÃ¡ o **README.md** atualizado, profissional e adaptado para essa estrutura de arquivos, ideal para seu portfÃ³lio:

-----

# ğŸ“Š Benchmark e AnÃ¡lise de Complexidade de Algoritmos

Este projeto consiste em um estudo prÃ¡tico e comparativo de **Estrutura de Dados e Algoritmos**, focado na anÃ¡lise de desempenho de **10 algoritmos de ordenaÃ§Ã£o** (Sorting Algorithms).

O objetivo Ã© confrontar a teoria da complexidade assintÃ³tica ($Big-O$) com o tempo de execuÃ§Ã£o real em Python, utilizando grandes volumes de dados e diferentes cenÃ¡rios de ordenaÃ§Ã£o (casos mÃ©dios aleatÃ³rios e piores casos inversamente ordenados).

-----

## ğŸš€ Como Executar este Projeto

Para reproduzir as anÃ¡lises e grÃ¡ficos em sua mÃ¡quina local, siga os passos abaixo:

### 1\. PrÃ©-requisitos

Certifique-se de ter o **Python 3.x** instalado e um ambiente para rodar Jupyter Notebooks (VS Code, Jupyter Lab ou Anaconda).

### 2\. InstalaÃ§Ã£o das DependÃªncias

Abra seu terminal e instale as bibliotecas necessÃ¡rias:

```bash
pip install numpy pandas matplotlib notebook
```

### 3\. Executando os Arquivos

A execuÃ§Ã£o Ã© dividida em duas etapas: geraÃ§Ã£o de dados e visualizaÃ§Ã£o.

1.  **Clone ou baixe o repositÃ³rio.**
2.  **GeraÃ§Ã£o dos Dados:**
      * Acesse a pasta `array archive`.
      * Execute o notebook **`arrays.ipynb`**.
      * *O que ele faz:* Implementa os algoritmos, executa os testes de estresse e salva os tempos brutos em arquivos `.npy` dentro desta mesma pasta.
3.  **AnÃ¡lise e GrÃ¡ficos:**
      * Volte para a raiz do repositÃ³rio.
      * Execute o notebook **`sort_benchmark.ipynb`**.
      * *O que ele faz:* LÃª os arquivos `.npy` gerados anteriormente, compila os dados em DataFrames e plota os grÃ¡ficos comparativos finais.

-----

## ğŸ› ï¸ Tecnologias Utilizadas

  * **Linguagem:** Python 3.12+
  * **Processamento NumÃ©rico:** NumPy
  * **AnÃ¡lise de Dados:** Pandas
  * **VisualizaÃ§Ã£o de Dados:** Matplotlib
  * **Ambiente de Desenvolvimento:** Jupyter Notebook

-----

## ğŸ§  Algoritmos Implementados

O estudo cobre trÃªs categorias de complexidade, permitindo visualizar o "salto" de performance entre diferentes abordagens lÃ³gicas.

### 1\. Algoritmos QuadrÃ¡ticos â€” $O(n^2)$

  * **Bubble Sort**
  * **Selection Sort**
  * **Insertion Sort**
  * **Shell Sort** (Otimizado com estratÃ©gia de *gap*, mas agrupado aqui pela performance em pequenos conjuntos).

### 2\. Algoritmos Log-Lineares â€” $O(n \log n)$

  * **Quick Sort** (EstratÃ©gia de pivÃ´: Ãºltimo elemento).
  * **Merge Sort** (DivisÃ£o e Conquista).
  * **Heap Sort** (Estrutura de Heap BinÃ¡ria).

### 3\. Algoritmos Lineares / DistribuiÃ§Ã£o â€” $O(n+k)$

  * **Bucket Sort**
  * **Counting Sort**
  * **Radix Sort**

-----

## ğŸ“‚ Estrutura do RepositÃ³rio

```text
â”œâ”€â”€ array archive/              # MÃ³dulo de Processamento e Dados Brutos
â”‚   â”œâ”€â”€ arrays.ipynb            # ImplementaÃ§Ã£o dos algoritmos e script de teste
â”‚   â”œâ”€â”€ list_*.npy              # Arquivos binÃ¡rios com os tempos de execuÃ§Ã£o salvos
â”‚   â””â”€â”€ ...
â”œâ”€â”€ resultados_medias.csv       # Tabela consolidada dos testes de Caso MÃ©dio
â”œâ”€â”€ resultados_piores_casos.csv # Tabela consolidada dos testes de Pior Caso
â”œâ”€â”€ sort_benchmark.ipynb        # Notebook de VisualizaÃ§Ã£o, GrÃ¡ficos e ConclusÃµes
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

-----

## ğŸ“ˆ Principais Insights e Resultados

A anÃ¡lise visual dos dados (disponÃ­vel em `sort_benchmark.ipynb`) revelou conclusÃµes importantes:

### 1\. O Abismo de Desempenho

Em escala logarÃ­tmica, a diferenÃ§a entre as classes de algoritmos Ã© brutal. Enquanto o **Bubble Sort** leva mais de 700 segundos para ordenar 50k elementos no pior caso, algoritmos como **Radix Sort** realizam a mesma tarefa em fraÃ§Ãµes de segundo (0.09s).

### 2\. A Instabilidade do Quick Sort

Apesar de ser extremamente rÃ¡pido no **Caso MÃ©dio** (dados aleatÃ³rios), o Quick Sort com pivÃ´ fixo degradou para uma performance quadrÃ¡tica $O(n^2)$ no **Pior Caso** (lista invertida), comportando-se de maneira semelhante aos algoritmos mais lentos.

### 3\. Robustez do Merge e Heap Sort

Estes algoritmos demonstraram consistÃªncia absoluta. As curvas de tempo para dados aleatÃ³rios e dados invertidos foram praticamente idÃªnticas, confirmando a estabilidade de $O(n \log n)$ independente da desordem da entrada.

### 4\. A Supremacia dos Algoritmos Lineares

Os algoritmos de distribuiÃ§Ã£o (**Counting, Radix, Bucket**) superaram todos os outros. O grÃ¡fico de "Caso MÃ©dio" mostra suas linhas praticamente coladas ao eixo X (tempo prÃ³ximo de zero), validando a complexidade $O(n+k)$ para ordenaÃ§Ã£o de inteiros.

-----